{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iQjUN2EIz2Ld"
      },
      "outputs": [],
      "source": [
        "from keras_facenet import FaceNet\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1967,)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(r'C:\\Users\\Raum\\Desktop\\jec\\code\\experimental\\array_of_frame\\gg.npy', 'rb') as f:\n",
        "    a = np.load(f)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedder = FaceNet()\n",
        "detector = MTCNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extraction_keras_lock(*file_name,show=None):\n",
        "  if type(file_name) is tuple:\n",
        "    file_name = [*file_name,]\n",
        "  result = []\n",
        "  for i in file_name:\n",
        "    image = Image.open(i).convert('RGB')\n",
        "    im_arr = np.array(image)\n",
        "    N=0\n",
        "    faces = detector.detect_faces(im_arr)\n",
        "    x1,y1,width,height = faces[N]['box'] # faces[N]['box']\n",
        "    x2,y2 = (x1+width),(y1+height)\n",
        "    face = im_arr[y1:y2,x1:x2] # ตัดเอาเฉพาะใบหน้า\n",
        "    image_face = Image.fromarray(face)\n",
        "    image_face= image_face.resize((224,224))\n",
        "    face_img = np.expand_dims(image_face,axis=0)\n",
        "    result.append(embedder.embeddings(face_img))\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extraction_keras_all_cv(im_arr):\n",
        "    position_crop = []\n",
        "    embedding_faces = []\n",
        "    position = []\n",
        "    faces = detector.detect_faces(im_arr)\n",
        "    \n",
        "    if faces == []:\n",
        "        return [],[]\n",
        "\n",
        "    for i in faces:\n",
        "        x1,y1,width,height = i['box']\n",
        "        x2,y2 = (x1+width),(y1+height)\n",
        "        position_crop.append([y1,y2,x1,x2])\n",
        "        position.append([x1,y1,x2,y2])\n",
        "\n",
        "    # print(len(position_crop))\n",
        "    for i in position_crop:\n",
        "        # print(i)\n",
        "        face = im_arr[i[0]:i[1],i[2]:i[3]]\n",
        "        image_face = cv2.resize(face,(224,224))\n",
        "        faces_crops = np.expand_dims(image_face,axis=0)\n",
        "        embedding_faces.append(embedder.embeddings(faces_crops))\n",
        "        # print(embedding_faces)\n",
        "    return embedding_faces,position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "image=cv2.imread(r'C:\\Users\\Raum\\Desktop\\jec\\code\\dataface\\pitha.jpg')\n",
        "im_arr = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "embedding_faces,position = extraction_keras_all_cv(im_arr)\n",
        "xx = extraction_keras_lock(r'C:\\Users\\Raum\\Desktop\\jec\\code\\dataface\\Pita.jpg',r'C:\\Users\\Raum\\Desktop\\jec\\code\\dataface\\siri.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[0.7874079]], dtype=float32),\n",
              " array([[0.2973188]], dtype=float32),\n",
              " array([[-0.03770198]], dtype=float32),\n",
              " array([[0.08064354]], dtype=float32),\n",
              " array([[0.27171814]], dtype=float32),\n",
              " array([[-0.05674545]], dtype=float32),\n",
              " array([[0.0596335]], dtype=float32),\n",
              " array([[0.05591889]], dtype=float32),\n",
              " array([[0.20720986]], dtype=float32),\n",
              " array([[0.06897811]], dtype=float32),\n",
              " array([[0.7230322]], dtype=float32)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "log_cosine_similarity = []\n",
        "\n",
        "Detection_check = np.zeros((len(position)))\n",
        "for j in range(len(xx)):\n",
        "\n",
        "    for i in range(len(position)):\n",
        "        similar = cosine_similarity(xx[j], embedding_faces[i])\n",
        "        log_cosine_similarity.append(similar)\n",
        "        if similar>0.55 and Detection_check[i] ==0 :\n",
        "            Detection_check[i] = 1\n",
        "            break\n",
        "\n",
        "for i in range(len(position)):\n",
        "    if Detection_check[i] == 1:\n",
        "          pass\n",
        "    else :\n",
        "        censor_region = (position[i][0],position[i][1],position[i][2],position[i][3])\n",
        "\n",
        "        censored_area = image[censor_region[1]:censor_region[3], censor_region[0]:censor_region[2]]\n",
        "\n",
        "        censored_width, censored_height = censored_area.shape[1], censored_area.shape[0]\n",
        "\n",
        "\n",
        "        pixel_size = 12\n",
        "        censored_area = cv2.resize(censored_area, (censored_width // pixel_size, censored_height // pixel_size))\n",
        "        censored_area = cv2.resize(censored_area, (censored_width, censored_height), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        image[censor_region[1]:censor_region[3], censor_region[0]:censor_region[2]] = censored_area\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[0.7874079]], dtype=float32),\n",
              " array([[0.2973188]], dtype=float32),\n",
              " array([[-0.03770198]], dtype=float32),\n",
              " array([[0.08064354]], dtype=float32),\n",
              " array([[0.27171814]], dtype=float32),\n",
              " array([[-0.05674545]], dtype=float32),\n",
              " array([[0.0596335]], dtype=float32),\n",
              " array([[0.05591889]], dtype=float32),\n",
              " array([[0.20720986]], dtype=float32),\n",
              " array([[0.06897811]], dtype=float32),\n",
              " array([[0.7230322]], dtype=float32)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv2.imwrite('ggggg.jpg',image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
